%\versoquote{When a person is determined to believe something, the very absurdity of the doctrine confirms them in their faith.}{Junius}
\chapter{Microscopic TLS Model}
\chapterprecis{The Microscopic TLS Model chapter}%TODO: Fill this in.
\loftchap{Microscopic TLS Model}

\section{Concept and background}
\section{Potential configuration}

\begin{equation}
    H = -\frac{\hbar^2}{2m_{oxy}}\nabla^2+V(\mathbf{r})
    \label{eq:OHam}
\end{equation}

\begin{table}[h]
\caption[Streitz-Mintmire Pair Constants]{\label{tab:smconsts} Empirical constants for the Streitz-Mintmire pair potentials~\cite{Streitz1994,Gale2003}.}
\centering
\begin{tabular}{ c*{5}{r@{.}l} } \toprule
Pair & \multicolumn{2}{c}{A} & \multicolumn{2}{c}{$\rho$} & \multicolumn{2}{c}{B} & \multicolumn{2}{c}{C} & \multicolumn{2}{c}{$r_0$}  \\ \midrule
Al--Al & 4&474755 & 0&991317 & 0&159472 & 5&949144 & 3&365875 \\
Al--O & 62&933909 & 0&443658 & 0&094594 & 9&985407 & 2&358570 \\
O--O & 3322&784218 & 0&291065 & 1&865072 & 16&822405 & 2&005092 \\ \bottomrule
\end{tabular}
\end{table}

\begin{figure}[htp]
\centering
\resizebox{0.8\columnwidth}{!}{\includestandalone{figures/mexhatproj}}
\caption[Potential Projections]{\label{fig:mexhatproj}\lin{1D} double wells (blue, solid) and harmonic wells (red, dashed) can be used to represent simple projections of a \lin{2D} potential onto the $x$ and $y$ axes. Left: two projected double wells is an example of a tetra-well. Right: a combination of one double well and a harmonic well reflects the hemi-tetra- case.}
\end{figure}

\section{Finite Grid}


\subsection{Derivation}
Following the discussion in \onlinecite{Holoborodko2009}: to calculate the numerical derivative of the function $f(x)$ one can approximate the local region about any point $x^*$ by an appropriate polynomial $P_m(x)$.
Derivatives of the polynomial are assumed to be equal to the derivative of the original function: $f\,'(x^*)\approx P\,'_m(x^*)$ and $f\,''(x^*)\approx P\,''_m(x^*)$ \etc

Sampling $f(x)$ at $N$ abscissas (where $N$ is odd) equidistant from $x^*$ such that

\begin{equation}
f_k = f(x_k), \quad x_k=x^*+kh, \quad \left\{k \in \mathds{Z} \vert -(N-1)/2 \leq k \leq  (N-1)/2 \right\}
\end{equation}

and interpolating points $\{(x_k,f_k)\}$ by a polynomial of degree $N-1$
\begin{equation}
P_{N-1}(x)=\sum_{j=0}^{N-1} a_j x^j,
\end{equation}

a solution can be found by obtaining the set of coefficients $\{a_j\}$ for the system of linear equations
\begin{equation}
\left\{P_{N-1}(x_k)=f_x\right\}.
\end{equation}

For reasons outlined \emph{vide infra} in \cref{sec:cdiffstep}, a centered formula of order $\mathcal{O}(h^6)$ is needed to obtain the error tolerance required to solve \cref{eq:OHam}, thus a $N=7$ point calculation.

The interpolating parabola \cref{eq:ploylinset} are

{\mathindent=0.5cm
\begin{align}
&\begin{cases}
    P_7(-3h) &= \quad f_{-3}\\
    P_7(-2h) &= \quad f_{-2}\\
    P_7(-h) &= \quad f_{-1}\\
    P_7(0) &= \quad f_{0}\\
    P_7(h) &= \quad f_{1}\\
    P_7(2h) &= \quad f_{2}\\
    P_7(3h) &= \quad f_{3}
  \end{cases} \nonumber \displaybreak[0]\\[0.2cm]
  \Rrightarrow
  &\begin{cases}
    a_0 - 3a_1h + 9a_2h^3 - 27a_3h^3 + 81a_4h^4 - 243a_5h^5 + 729a_6h^6 &= f_{-3}\\
    a_0 - 2a_1h + 4a_2h^2 - 8a_3h^3 + 16a_4h^4 - 32a_5h^5 + 64a_6h^6 &= f_{-2}\\
    a_0 - a_1h + a_2h^2 - a_3h^3 + a_4h^4 - a_5h^5 + a_6h^6 &= f_{-1}\\
    a_0 &= f_{0}\\
    a_0 + a_1h + a_2h^2 + a_3h^3 + a_4h^4 + a_5h^5 + a_6h^6 &= f_{1}\\
    a_0 + 2a_1h + 4a_2h^2 + 8a_3h^3 + 16a_4h^4 + 32a_5h^5 + 64a_6h^6 &= f_{2}\\
    a_0 + 3a_1h + 9a_2h^3 + 27a_3h^3 + 81a_4h^4 + 243a_5h^5 + 729a_6h^6 &= f_{3}
  \end{cases}
\end{align}
}
Solving this set of simultaneous equations for $\{a_j\}$ yields
\begin{equation}
\begin{dcases}
a_0 &= f_{0}\\
a_1 &= \frac{-f_{-3}+9f_{-2}-45f_{-1}+45f_{1}-9f_{2}+f_{3}}{12h}\\
a_2 &= \frac{2f_{-3}-27f_{-2}+270f_{-1}-490f_{0}+270f_{1}-27f_{2}+2f_{3}}{360h^2}\\
&\vdots
\end{dcases}
\end{equation}

Assuming $x^* = 0$ for simplicity, it's clear that $f\,'(0) \approx P\,'_7(0) = a_1$ and therefore
{\mathindent=0.5cm
\begin{equation}
\begin{split}
f\,''(0)&\approx P\,''_7(0)=2a_2\\
&=\frac{2f_{-3}-27f_{-2}+270f_{-1}-490f_{0}+270f_{1}-27f_{2}+2f_{3}}{180h^{2}}+\mathcal{E}_{trunc}(f,h).
\label{eq:cdiffe}
\end{split}
\end{equation}
}
\subsection{Truncation Error}\label{sec:truncerr}

The truncation error $\cramped{E_{trunc}(f,h)}$ is a consequence of curtailing the interpolating parabola to the $(N-1)th$ degree.
The above method, whilst concise and practical for obtaining the $N$ point central formula, is not the entire picture.
An alternative, more general approach is to start with Taylor expansions about $x$ for $f(x_k)$~\cite{Cyrus1968,Mathews2004}.
For second derivative solutions, $N+1$ degree expansions are required in the form $f(x) = P_7(x)+E_7(x)$.

%{\mathindent=0.2cm
\begin{align}
\MoveEqLeft f(x\pm h) = \nonumber\\
&f(x)\pm f\,'(x)h+\frac{f\,^{''}(x)h^2}{2!}\pm \frac{f\,^{(3)}(x)h^3}{3!}+\frac{f\,^{(4)}(x)h^4}{4!}\pm \frac{f\,^{(5)}(x)h^5}{5!}\nonumber\\
&+\frac{f\,^{(6)}(x)h^6}{6!}\pm \frac{f\,^{(7)}(x)h^7}{7!}+\frac{f\,^{(8)}(x)h^8}{8!}+\mathcal{O}(h^9)\displaybreak[0]\\[0.2cm]
\MoveEqLeft f(x\pm 2h) = \nonumber\\
&f(x)\pm 2f\,'(x)h+\frac{4f\,^{''}(x)h^2}{2!}\pm \frac{8f\,^{(3)}(x)h^3}{3!}+\frac{16f\,^{(4)}(x)h^4}{4!}\pm \frac{32f\,^{(5)}(x)h^5}{5!}\nonumber\\
&+\frac{64f\,^{(6)}(x)h^6}{6!}\pm \frac{128f\,^{(7)}(x)h^7}{7!}+\frac{256f\,^{(8)}(x)h^8}{8!}+\mathcal{O}(h^9)\displaybreak[0]\\[0.2cm]
\MoveEqLeft f(x\pm 3h) = \nonumber\\
&f(x)\pm 3f\,'(x)h+\frac{9f\,^{''}(x)h^2}{2!}\pm \frac{27f\,^{(3)}(x)h^3}{3!}+\frac{81f\,^{(4)}(x)h^4}{4!}\pm \frac{243f\,^{(5)}(x)h^5}{5!}\nonumber\\
&+\frac{729f\,^{(6)}(x)h^6}{6!}\pm \frac{2187f\,^{(7)}(x)h^7}{7!}+\frac{6561f\,^{(8)}(x)h^8}{8!}+\mathcal{O}(h^9)
\end{align}
%}

Calculating the difference between each set of expansions at this juncture would allow one to obtain the first derivative, however the second derivative is required in this instance.
Summing the terms will remove the odd degree terms

\begin{align}
\MoveEqLeft f(x+h)+f(x-h) = 2f(x)+f\,^{''}(x)h^2\nonumber \\ &+\frac{2f\,^{(4)}(x)h^4}{4!}+\frac{2f\,^{(6)}(x)h^6}{6!}+\frac{2f\,^{(8)}(x)h^8}{8!}+\mathcal{O}(h^9)\label{eq:fxh}\displaybreak[0]\\[0.2cm]
\MoveEqLeft f(x+2h)+f(x-2h) = 2f(x)+4f\,^{''}(x)h^2\nonumber \\
&+\frac{32f\,^{(4)}(x)h^4}{4!}+\frac{128f\,^{(6)}(x)h^6}{6!}+\frac{512f\,^{(8)}(x)h^8}{8!}+\mathcal{O}(h^9)\label{eq:fx2h}\displaybreak[0]\\[0.2cm]
\MoveEqLeft f(x+3h)+f(x-3h) = 2f(x)+9f\,^{''}(x)h^2\nonumber \\
&+\frac{162f\,^{(4)}(x)h^4}{4!}+\frac{1458f\,^{(6)}(x)h^6}{6!}+\frac{13122f\,^{(8)}(x)h^8}{8!}+\mathcal{O}(h^9)\label{eq:fx3h}
\end{align}

leaving a set of equations with fourth and sixth degree terms which need be eliminated in order to arrive at an equation similar to \cref{eq:cdiffe}.
The series can also be truncated at this point at the eighth degree term, which exists at points $\{c_k\}$.
The equation $72\times$\cref{eq:fx2h}$-2\times$\cref{eq:fx3h}$-270\times$\cref{eq:fxh} (changing to the $f_k$ convention) yields

{\mathindent=0.2cm
\begin{align}
\MoveEqLeft 27f_{2}+27f_{-2}-2f_{3}-2f_{-3}-270f_{1}-270f_{-1} = \nonumber\\
&-490f(x)-180f\,''(x)h^2+\frac{13824f^{(8)}(c_2)-26244f^{(8)}(c_3)-540f^{(8)}(c_1)}{8!}\label{eq:truncsim}
\end{align}
}

If $f \in \mathds{C}^N [a,b]$, then it follows that $\{x_k\} \in [a,b]$.
Furthermore, $\exists c = \{c_k\} \in [a,b]$ such that if $f^{(8)}(x)$ has one sign and its magnitude does not change rapidly, $c \in [x-3h,x+2h]$

\begin{equation}
 13824f\,^{(8)}(c_2)-26244f\,^{(8)}(c_3)-540f\,^{(8)}(c_1) = -12960f\,^{(8)}(c).\label{eq:ctrunc}
\end{equation}

Equation \cref{eq:ctrunc} can now be substituted into \cref{eq:truncsim} and the result solved for $f\,''(x)$

{\mathindent=0.5cm
\begin{equation}
f\,''(x) = \frac{2f_{-3}-27f_{-2}+270f_{-1}-490f_{0}+270f_{1}-27f_{2}+2f_{3}}{180h^{2}}-\frac{f\,^{(8)}(c)h^6}{560},\label{eq:sptetrunc}
\end{equation}
}

resulting in the truncation error

\begin{equation}
\mathcal{E}_{trunc}(f,h) = -\frac{f\,^{(8)}(c)h^6}{560} = \mathcal{O}(h^6).\label{eq:etrunc}
\end{equation}

\subsection{Round-off Error and Step Size Optimisation}\label{sec:cdiffstep}

Computers also introduce floating point round-off errors into the mix, thus truncation is not the only error source that needs to be addressed.
Let $f_k = y_k +e_k$, where $e_k$ is defined as the error in computing $f(x_k)$. With this treatment, \cref{eq:sptetrunc} can be expanded to
\begin{align}
\MoveEqLeft f\,''(x_0) = \nonumber\\
&\frac{2y_{-3}-27y_{-2}+270y_{-1}-490y_{0}+270y_{1}-27y_{2}+2y_{3}}{180h^{2}}+\mathcal{E}(f,h),\label{eq:sptye}
\end{align}

where the error term now includes both round-off and truncation errors

{\mathindent=0.5cm
\begin{align}
\MoveEqLeft \mathcal{E}(f,h) = \nonumber\\
&\frac{2e_{-3}-27e_{-2}+270e_{-1}-490e_{0}+270e_{1}-27e_{2}+2e_{3}}{180h^{2}}-\frac{f\,^{(8)}(c)h^6}{560}.
\end{align}
}

Each error $e_k$ is assumed to be cumulative and of the same magnitude $\epsilon$ \ie $\abs{e_k} \leq \epsilon$.
To bound the error, a second assumption can be imposed on the truncation such that $\abs{f\,^{(8)}(c)} \leq M$ to introduce the condition

\begin{equation}
\abs{\mathcal{E}(f,h)} \leq \frac{272\epsilon}{45h^2}+\frac{Mh^6}{560}.\label{eq:cdifferrtot}
\end{equation}

It's clear from \cref{eq:cdifferrtot} that the truncation and round-off errors are inversely proportional (but not equal) for any choice of $h$, which is commonly referred to as the \emph{step-size dilemma}.
Expanding the central difference formula to $\mathcal{O}(h^6)$ increases the accuracy of over simpler methods like \cref{eq:simplecdiff} (which is $\mathcal{O}(h^2)$), where for a smaller $h$, the round-off error increases as the truncation error decreases at the same rate.

An optimal step size $h$ can be found which minimises the right hand side of \cref{eq:cdifferrtot}. Let

\begin{align}
g(h) &= \frac{272\epsilon}{45h^2}+\frac{Mh^6}{560}\\[0.2cm]
g'(h) &= \frac{544\epsilon}{45h^3}+\frac{3Mh^5}{280}.
\end{align}

Setting $g'(h) = 0$ and solving for $h$ obtains the optimal step:

\begin{equation}
h = \left(\frac{30464\epsilon}{27M}\right)^{1/8}.\label{eq:stepgen}
\end{equation}
for particular values of the error magnitude $\epsilon$ and the maximal truncation bound $M = \mathrm{max}_{[a,b]}\left(\abs{f\,^{(8)}(c)}\right)$.

Since there is no completely analytic form of Streitz Mintmire, finding the truncation bound directly via its eighth derivative is unfeasible.
However, the functional form does not differ from a harmonic oscillator far away from the origin (see section \xxx{Add in the mex hat section}x and \cref{fig:mexhatproj}) -- which has a simple analytic solution and can serve as an analogue.

The hamiltonian of particle in a one dimensional quantum harmonic oscillator can be described as

\begin{equation}
\widehat{H} = \frac{\widehat{p}^2}{2m}+\frac{1}{2}m\omega^2\widehat{x}^2\label{eq:hamho}
\end{equation}

where $m$ is the particle's mass and $ω$ is the angular frequency of the oscillator.
Two operators, $\widehat{x} = x$ for position and $\widehat{p} = -i\hbar \frac{\partial}{\partial x}$ for momentum describe the complete Schr\"{o}dinger equation, which (after separation of variables) takes its time independent form:

\begin{equation}
-\frac{\hbar^2}{2m}\frac{\partial^2 \Psi}{\partial x^2}+\frac{1}{2}m\omega^2x^2 \Psi = E\Psi,
\label{eq:hamti}
\end{equation}

with the family of solutions for the wavefunctions
\begin{equation}\psi_n(x) = \frac{1}{\sqrt{2^n\,n!}}\left(\frac{m\omega}{\hbar\pi}\right)^{1/4}e^{
- \frac{m\omega x^2}{2 \hbar}} H_n\left(\sqrt{\frac{m\omega}{\hbar}} x \right),\qquad n = 0,1,2,\ldots\\
H_n(x)=(-1)^n e^{x^2}\frac{\mathrm{d}^n}{\mathrm{d}x^n}\left(e^{-x^2}\right)
\end{equation}

Selecting the ground state ($n=0$) and differentiating to the eighth degree, the equation that will satisfy the truncation bound is

\begin{align}
\MoveEqLeft \Psi_0^{(8)}(x) = \nonumber\\
&\left(\frac{m\omega}{\hbar^2}\right)^4\left(\frac{m\omega}{\hbar\pi}\right)^{1/4}\left[(m\omega x^2)^4-28 (m\omega x^2)^3\hbar\right.\nonumber\\
&\left.+210(m\omega x^2)^2\hbar ^2-420m\omega x^2\hbar^3+105\hbar^4\right]e^{-\frac{m\omega x^2}{2\hbar}}.
\label{eq:eightwfn}
\end{align}

The functional form of \cref{eq:eightwfn} indicates a maximal value at $x=0$ such that

\begin{equation}
M = \lim_{x \to 0} \abs{\Psi_0^{(8)}(x)} = \abs{105\left(\frac{m\omega}{\hbar^2}\right)^4\left(\frac{m\omega}{\hbar\pi}\right)^{1/4}}
\label{eq:Mlimit}
\end{equation}
recalling $M = \mathrm{max}_{[a,b]}\left(\abs{f\,^{(8)}(c)}\right)$.

An approximation of the harmonic oscillator using the Hamiltonian \cref{eq:hamho} is valid near the minimum of any potential function, thus

\begin{align}
V(x) &= \frac{1}{2}m\omega^2\hat{x}^2, \qquad \omega=\sqrt{\frac{k}{m}}\label{eq:vharm}\\
     &= \frac{1}{2}k\hat{x}^2
\end{align}

can be connected to the Streitz Mintmire potential through the relationship $V(x_{0})=V_{SM}(x_{0})$, if Streitz Mintmire has one local minima at $x=0$.

As discussed in \xxx{Section on units}, $V_{SM}$ is measured in [μeV] with $x$ in [Å], whereas $V$ is measured in [J] against [m].
Converting a Streitz Mintmire configuration to this unit scheme and fitting a parabola to the minima, a value of $k=938$ is found.
\Cref{fig:harmsm} shows the fit for this value, which is comparatively representational to a large range of cluster configurations.

\begin{figure}[htp]
\centering
\hspace{-1cm}\resizebox{0.7\columnwidth}{!}{\includestandalone{figures/harmsm}}
\caption[Harmonic Approximation to Strietz Mintmire]{\label{fig:harmsm}A parabolic fit to the minima of a \lin{1D} Strietz Mintmire potential.}
\end{figure}

The associated angular frequency is therefore
\begin{equation}
\omega=\sqrt{\frac{938}{2.65\ten{-26}}}=1.879\ten{14}
\end{equation}
using the mass of an oxygen atom, which can now be used to solve \cref{eq:Mlimit} for $M = 1.847\ten{98}$.
The final term yet to be discussed from \cref{eq:cdifferrtot} is $\epsilon$.
This value is the floating-point relative accuracy of the platform and software under which the central difference is being performed.
On various \texttt{Linux} distributions and \texttt{Windows 7}, \texttt{Matlab 2014b} provides two values for $\epsilon$: single precision $\epsilon_s = 1.192\ten{-7}$ and double $\epsilon_d = 2.220\ten{-16}$.

...

More complex error analysis to be found in \cite{Mathur2012}


\section{New version of this section}

\begin{enumerate}
  \item New introduction based off of \citeauthor{Mathur2012}'s first chapter
  \item Discuss inherent errors and issues with finding an optimum step size
  \item Quick overview of AutoDX, mostly cite \cite{Mathur2012} rather than going into too much detail of the algo, although make sure maths is complete
  \item Approximate \cref{eq:OHam} with harmonic oscillator (using \cref{fig:harmsm} subsection), obtaining an analytic expression for $\Psi$, so we can apply AutoDX to $\nabla^2$ (using a simple $\mathcal{O}(h^2)$). Will need to use the dimensionless equation b.c. the real value one borks (too many orders of mag I think).
  \item Discuss memory constraints. Need to make larger step size without cutting out accuracy
  \item Derive seven point
  \item Compare $h_{opt}$ and $\abs{TE_n}$ with 3 point
  \item Connect both to real units, find $C_n$ \etc, then total error
  \item Be fucking done with this shit.
\end{enumerate}

\section{Solving Derivatives Numerically}
The Streitz Mintmire potential \cite{Streitz1994} is an assemblage of many functional forms and integrals, which in total are not completely analytic over all regions of importance.
Therefore $\nabla^2$ in \cref{eq:OHam} will also require numerical treatment over a discrete grid of spatial coordinates.
A number of methods exist for this problem; most of which introduce errors from various approximations and platform limitations.
Models exist that effectively remove these errors, but are usually incredibly mathematically complex and problem specific: for example, a variational model which calculates an optimised three-finite-burn lunar escape trajectory~\cite{Ocampo2012}.

On the simpler end of the spectrum, finite difference algorithms are useful for boundary value problems (where forward and backward methods are usually applied), and for ordinary and partial differential equations.
If a first order ODE (or PDE) of the form $f(x)$ can be evaluated both left and right of $x$, the central difference method can be used where abscissas are chosen symmetrically about $x$, which takes the form
\nomdef{AODE}{ODE}{Ordinary Differential Equation}
\nomdef{APDE}{PDE}{Partial Differential Equation}
\begin{equation}
f\,'(x) \approx \frac{f(x+h)-f(x+h)}{2h},\label{eq:simplecdiff}
\end{equation}
where $h$ is some step size.
The step size controls the accuracy of the computed derivative, which is unfortunately bound by two factors.
If the step size is too small, numerical roundoff errors cause accuracy issues; on the other hand, a step size too large sees mathematical truncation errors dominate.
Finding an optimal balance for the step size is also dependent on the specific value of $f\,'(x)$ being calculated, which may not be appropriate for a similar set of values. 
This problem, known as `the step size dilemma' has generated a number of investigations in an attempt to find a middle ground between simple finite difference methods with strong bounding conditions and the highly domain specific models like the variation model described above.

The complex step method (exploiting complex perturbations of the general Taylor series) yields no subtractive cancellation errors~\cite{Squire1998}, which exist in the real spaced Taylor series finite difference methods; \cref{eq:simplecdiff} is a simple example of this.
However, for many years this statement was only true for the first order derivative -- higher orders were shown to have as many cancellation errors as their finite difference counterparts.
This method was therefore excluded as a candidate for the model constructed for this thesis, as it would perform on par with standard finite difference methods for the second order derivative we wish to compute.
After much of the base code for this model had been constructed, a generalised, arbitrary order derivative complex step algorithm was published~\cite{Lantoine2012}.
This algorithm may improve the error contribution of the models' final implementation, although this has not been investigated.

A second possible successor to finite difference is automatic differentiation (AD). 
\nomdef{AAD}{AD}{Automatic Differentiation}
The premise of this algorithm isn't necessarily mathematical in nature, but capitalises on the fact that computers are methodological reductionists and ultimately only execute simple arithmetic operations no matter how complicated the actual computation is.
Repeatedly applying the chain rule to these operations, AD can compute the derivative to working precision~\cite{Kedem1980}.
There a two methods to implement this algorithm; neither is straightforward. 
One uses special AD preprocessors that analyse each function call, break it up instruction by instruction and generates a new function that computes derivatives.
Method two involves operator overloading that can generate code at compile time, which in a JIT accelerated environment like \texttt{Matlab} is unfeasible.

Both AD and complex step require access to functions at the source code level, meaning calls to third party libraries like \texttt{BLAS} and \texttt{LAPACK} (which are used in this model's implementation \xxx{section on lapack}) become increasingly over complicated.

For these reasons, it was decided to implement our model using a finite central difference method, paying close attention to the inherent error in exchange for relative computational simplicity.

\section{Understanding Finite Difference Methods}

All finite difference methods involve truncating a Taylor series expansion of a function $f(x)$ about $x^*$ after a certain number of terms

\begin{equation}
    f(x) = f(x^*) + f\,'(x)(x-x*) + \cdots + R_n.
\end{equation}

The discarded, higher order remainder terms $R_n$, are considered to contribute a negligible error to the approximation assuming a sufficiently small step size $h$.

\begin{equation}
    R_n = \sum_{m=n}^\infty \frac{f\,^{(m)}(x^*)}{m!}(x-x^*)^m
\end{equation}

It can be shown using the integral calculus derivation of the Taylor series that the $n^{th}$ derivative can be bound over the interval $[x^*, x]$, \ie $a\leq f\,^{(n)}(x) \leq c$~\cite{Greenberg1978}.
Furthermore, $\exists b \in [a,c]$ such that the remainder can be written as

\begin{equation}
   R_n = b \frac{(x-x^*)^n}{n!}.
\end{equation}

The Intermediate Value Theorem can be invoked at this stage to posit some point $\xi \in [x^*,x]$ exists for which $f\,^{(n)}(\xi)$ will equal the unknown parameter $b$.
$R_n$ in this form is called the Lagrange remainder.
While there is no known method to determine a value of $\xi$ exactly for a general function, it is useful to express the $n^{th}$ order Taylor series in terms of the Lagrange remainder:

\begin{equation}
    f(x) = \sum_{m=0}^n \frac{f\,^{(m)}(x^*)}{m!}(x-x^*)^m + \frac{f\,^{(n+1)}(\xi)}{(n+1)!}(x-x^*)^{n+1}, \quad \xi \in [x^*,x].
\end{equation}

...

Mathews2004 Holoborodko2009 Cyrus1968 Mathur2012

Following the discussion in \onlinecite{Holoborodko2009}: to calculate the numerical derivative of the function $f(x)$ one can approximate the local region about any point $x^*$ by an appropriate polynomial $P_m(x)$.
Derivatives of the polynomial are assumed to be equal to the derivative of the original function: $f\,'(x^*)\approx P\,'_m(x^*)$ and $f\,''(x^*)\approx P\,''_m(x^*)$ \etc

Sampling $f(x)$ at $N$ abscissas (where $N$ is odd) equidistant from $x^*$ such that

\begin{equation}
f_k = f(x_k), \quad x_k=x^*+kh, \quad \left\{k \in \mathds{Z} \vert -(N-1)/2 \leq k \leq  (N-1)/2 \right\}
\end{equation}

and interpolating points $\{(x_k,f_k)\}$ by a polynomial of degree $N-1$
\begin{equation}
P_{N-1}(x)=\sum_{j=0}^{N-1} a_j x^j,
\end{equation}

a solution can be found by obtaining the set of coefficients $\{a_j\}$ for the system of linear equations
\begin{equation}
\left\{P_{N-1}(x_k)=f_x\right\}.
\label{eq:ploylinset}
\end{equation}



